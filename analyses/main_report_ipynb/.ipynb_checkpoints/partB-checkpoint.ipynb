{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b75dd9-ed9f-40fc-802e-68b697b717b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Single-Cell Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ba53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up logging ##\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Starting single-cell data wrangling...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Kang et al. single-cell dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5dde1-148e-4350-bd4f-135f5cbbaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load single-cell atalas data complet\n",
    "import os\n",
    "\n",
    "## Data directory\n",
    "dataDir = \"../../../../data/atlas_dataset\"\n",
    "sc_dict = {os.path.splitext(f)[0]: os.path.join(dataDir, f) for f in sc_files}\n",
    "\n",
    "## Make sure files exist\n",
    "samples = {k: v for k, v in sc_dict.items() if os.path.exists(v)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datadir = \"../../../../data/genexcell/\"\n",
    "#h5ad_files = [f for f in os.listdir(datadir) if f.endswith('.h5ad')]\n",
    "#sc_dict = {os.path.splitext(f)[0]: os.path.join(datadir, f) for f in h5ad_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cebcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data from genexcell\n",
    "\n",
    "# import cellxgene_census\n",
    "\n",
    "# census = cellxgene_census.open_soma(census_version=\"latest\")\n",
    "# census[\"census_info\"][\"summary\"].read().concat().to_pandas()\n",
    "\n",
    "# datasets = census[\"census_info\"][\"datasets\"].read().concat().to_pandas()\n",
    "# datasets[\"citation\"]\n",
    "\n",
    "# # dataset_ids = {\"scRNAseq\": \"02792605-4760-4023-82ad-40fc4458a5db\", \"snRNAseq\": \"1873a18a-66fd-4a4d-8277-a872c93f5b59\"}\n",
    "# dataset_ids = {\"ICB\": \"09595871-5cde-4351-88f9-b3c37b3ed466\"}\n",
    "\n",
    "\n",
    "\n",
    "# # Check each dataset ID from the dictionary and collect matching rows\n",
    "# matching_rows = []\n",
    "# for name, dataset_id in dataset_ids.items():\n",
    "#     is_present = dataset_id in datasets['dataset_id'].values\n",
    "#     if is_present:\n",
    "#         row_indices = datasets[datasets['dataset_id'] == dataset_id].index.tolist()\n",
    "#         print(f\"{name} ({dataset_id}): Present in rows {row_indices}\")\n",
    "#         matching_rows.extend(row_indices)\n",
    "#     else:\n",
    "#         print(f\"{name} ({dataset_id}): Not found\")\n",
    "\n",
    "# # Create subset DataFrame with only the matching rows\n",
    "# if matching_rows:\n",
    "#     datasubset = datasets.loc[matching_rows]\n",
    "#     print(f\"\\nCreated subset with {len(datasubset)} rows\")\n",
    "#     print(datasubset[['dataset_id']].head())  # Show the dataset_id column to verify\n",
    "# else:\n",
    "#     print(\"No matching rows found\")\n",
    "\n",
    "\n",
    "# ## Check publication\n",
    "# datasubset[\"collection_doi_label\"]\n",
    "\n",
    "# ## Retrieve cells\n",
    "\n",
    "# import cellxgene_census\n",
    "\n",
    "# # Get the dataset IDs as a list\n",
    "# dataset_id_list = list(dataset_ids.values())\n",
    "\n",
    "# census = cellxgene_census.open_soma()\n",
    "# keys = list(census[\"census_data\"][\"homo_sapiens\"].obs.keys())\n",
    "\n",
    "# # Query the census to get an AnnData object\n",
    "# with cellxgene_census.open_soma() as census:\n",
    "#     adata = cellxgene_census.get_anndata(\n",
    "#         census=census,\n",
    "#         organism=\"Homo sapiens\",  # or \"mus_musculus\" depending on your data\n",
    "#         measurement_name=\"RNA\",\n",
    "#         obs_value_filter=f\"dataset_id in {dataset_id_list}\",\n",
    "#         var_value_filter=None,  # You can add gene filtering here if needed\n",
    "#         obs_column_names=[\"soma_joinid\", \"dataset_id\", \"assay\", \"disease\", 'cell_type', 'cell_type_ontology_term_id','tissue','tissue_ontology_term_id'],\n",
    "#         var_column_names= [\"soma_joinid\", \"feature_id\", \"feature_name\"]\n",
    "#     )\n",
    "\n",
    "# print(f\"AnnData object created with {adata.n_obs} cells and {adata.n_vars} genes\")\n",
    "# print(adata.obs['dataset_id'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adata.obs['cell_type'].value_counts()\n",
    "\n",
    "# ## Remove NAs\n",
    "# import numpy as np\n",
    "# import scipy.sparse\n",
    "# import scanpy as sc\n",
    "\n",
    "# # First clean NaN values from the main data\n",
    "# if scipy.sparse.issparse(adata.X):\n",
    "#     # For sparse matrices\n",
    "#     adata.X.data = np.nan_to_num(adata.X.data, nan=0.0)\n",
    "# else:\n",
    "#     # For dense matrices\n",
    "#     adata.X = np.nan_to_num(adata.X, nan=0.0)\n",
    "\n",
    "# print(\"NaN values replaced with 0 in main matrix\")\n",
    "\n",
    "\n",
    "# # Minimal filtering\n",
    "# sc.pp.filter_genes(adata, min_cells=1)\n",
    "\n",
    "# # Set feature_name as the new var_names (index)\n",
    "# adata.var_names = adata.var['feature_name']\n",
    "\n",
    "# # Optional: Make the names unique if there are duplicates\n",
    "# adata.var_names_make_unique()\n",
    "\n",
    "# sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "# sc.pp.log1p(adata)\n",
    "\n",
    "# adata.raw = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f786594",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all files and create integrated AnnData object\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "adata_dict = {k: sc.read_h5ad(v) for k, v in sc_dict.items()}\n",
    "\n",
    "for key, adata in adata_dict.items():\n",
    "    print(f\"{key}: {adata.shape}\")\n",
    "\n",
    "## Concatenate all single-cell datasets\n",
    "oSC = sc.concat(adata_dict.values(), label=\"sample\", join='outer')\n",
    "\n",
    "## No count data are provided - we'll create a count layer. \n",
    "counts_sparse = oSC.X.copy()\n",
    "counts_sparse.data = np.rint(np.power(10, counts_sparse.data.astype(float))).astype(int)\n",
    "\n",
    "oSC.layers[\"counts\"] = counts_sparse\n",
    "\n",
    "## Add patientID column to metadata\n",
    "unique_patients = {name: f'P{i+1}' for i, name in enumerate(oSC.obs['Patient'].unique())}\n",
    "oSC.obs['patientID'] = oSC.obs['Patient'].map(unique_patients)\n",
    "\n",
    "oSC.obs[\"Organ_origin\"] = oSC.obs[\"Organ_origin\"].str.replace(r\"[ _-]\", \"\", regex=True)\n",
    "\n",
    "oSC.obs[\"sampleName\"] = (\n",
    "    oSC.obs[\"Organ_origin\"].astype(str) + \"_\" +\n",
    "    oSC.obs[\"Tissue\"].astype(str) + \"_\" +\n",
    "    oSC.obs[\"patientID\"].astype(str)\n",
    ")\n",
    "\n",
    "oSC.obs[\"sampleName\"] = (\n",
    "    oSC.obs[\"sampleName\"]\n",
    "    .str.replace(\"AdrenalGland\", \"AdrenalGl\")\n",
    "    .str.replace(\"SmallIntestine\", \"SIntestin\")\n",
    "    .str.replace(\"Neuroendocrine\", \"Neuroend\")\n",
    "    .str.replace(\"FallopianTube\", \"FallopTube\")\n",
    ")\n",
    "\n",
    "oSC.obs[\"sampleName\"] = (\n",
    "    oSC.obs[\"sampleName\"]\n",
    "    .str.replace(\"SIntestin\", \"SIntestine\")\n",
    ")\n",
    "\n",
    "## Checking ##\n",
    "matches = oSC.obs[oSC.obs[\"sampleName\"].str.contains(r\"_P1(?!\\d)\", regex=True)][\"sampleName\"]\n",
    "print(matches)\n",
    "\n",
    "## filtering for patients with tumor and normal samples\n",
    "tn_patients = (\n",
    "    oSC.obs.groupby(\"patientID\")[\"Tissue\"]\n",
    "    .transform(lambda x: set([\"Tumor\", \"Normal\"]).issubset(set(x)))\n",
    ")\n",
    "oSC = oSC[tn_patients].copy()\n",
    "\n",
    "## Check organ representation ##\n",
    "df = oSC.obs[['sampleName', 'Tissue', 'Organ_origin']]\n",
    "df = df.drop_duplicates().sort_values(by=['Organ_origin', 'Tissue', 'sampleName'])\n",
    "df.value_counts('Organ_origin')\n",
    "\n",
    "## Remove all samples with less than 10 samples:\n",
    "counts = df['Organ_origin'].value_counts()\n",
    "df_filtered = df[df['Organ_origin'].isin(counts[counts >= 10].index)]\n",
    "\n",
    "\n",
    "## Filtering the anndata object ##\n",
    "oSC = oSC[oSC.obs['sampleName'].isin(df_filtered['sampleName'])].copy()\n",
    "\n",
    "## save object\n",
    "oSC.write_h5ad(\"../../../../data/kang_tn_filtered.h5ad\")\n",
    "\n",
    "#########################################\n",
    "## Create count and Intensity dataset  ##\n",
    "#########################################\n",
    "\n",
    "## counts ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# Get the counts matrix (cells x genes) and sample labels\n",
    "counts = oSC.layers[\"counts\"]\n",
    "sample_names = oSC.obs['sampleName'].values\n",
    "\n",
    "# Get unique sample names and their indices\n",
    "unique_samples, inverse = np.unique(sample_names, return_inverse=True)\n",
    "\n",
    "# Prepare an empty sparse matrix for pseudobulk (samples x genes)\n",
    "pseudobulk = sparse.lil_matrix((len(unique_samples), counts.shape[1]), dtype=counts.dtype)\n",
    "\n",
    "# For each sample, compute the mean across cells\n",
    "for i, sample in enumerate(unique_samples):\n",
    "    idx = np.where(inverse == i)[0]\n",
    "    # mean along axis 0 (cells)\n",
    "    pseudobulk[i, :] = counts[idx].mean(axis=0)\n",
    "\n",
    "# Convert to DataFrame (optional)\n",
    "pseudobulk_df = pd.DataFrame(\n",
    "    pseudobulk.toarray(),\n",
    "    index=unique_samples,\n",
    "    columns=oSC.var_names\n",
    ")\n",
    "\n",
    "pseudobulk_df = pseudobulk_df.T\n",
    "\n",
    "# Remove zero only rows\n",
    "pseudobulk_df = pseudobulk_df[(pseudobulk_df != 0).any(axis=1)]\n",
    "\n",
    "pseudobulk_df['gene_id'] = pseudobulk_df.index\n",
    "\n",
    "# Move gene_id to the first column (optional)\n",
    "cols = ['gene_id'] + [col for col in pseudobulk_df.columns if col != 'gene_id']\n",
    "pseudobulk_df = pseudobulk_df[cols]\n",
    "\n",
    "# Save as tab-delimited file\n",
    "pseudobulk_df.to_csv('pseudobulk.tsv', sep='\\t', index=False)\n",
    "pseudobulk_df = pseudobulk_df[cols]\n",
    "\n",
    "pseudobulk_df.to_csv('../../../../data/kang.tn.filtered.pseudobulk.counts.txt', sep='\\t', index=False)\n",
    "\n",
    "gene_ids = pseudobulk_df['gene_id'].tolist()\n",
    "\n",
    "## get gene_ids to subset expression pseudobulk\n",
    "\n",
    "## expression intensity ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# Get the counts matrix (cells x genes) and sample labels\n",
    "counts = oSC.X\n",
    "sample_names = oSC.obs['sampleName'].values\n",
    "\n",
    "# Get unique sample names and their indices\n",
    "unique_samples, inverse = np.unique(sample_names, return_inverse=True)\n",
    "\n",
    "# Prepare an empty sparse matrix for pseudobulk (samples x genes)\n",
    "pseudobulk = sparse.lil_matrix((len(unique_samples), counts.shape[1]), dtype=counts.dtype)\n",
    "\n",
    "# For each sample, compute the mean across cells\n",
    "for i, sample in enumerate(unique_samples):\n",
    "    idx = np.where(inverse == i)[0]\n",
    "    # mean along axis 0 (cells)\n",
    "    pseudobulk[i, :] = counts[idx].mean(axis=0)\n",
    "\n",
    "# Convert to DataFrame (optional)\n",
    "pseudobulk_df = pd.DataFrame(\n",
    "    pseudobulk.toarray(),\n",
    "    index=unique_samples,\n",
    "    columns=oSC.var_names\n",
    ")\n",
    "\n",
    "pseudobulk_df = pseudobulk_df.T\n",
    "pseudobulk_df = pseudobulk_df.round(3)\n",
    "\n",
    "# keep only rows that are also present in the countset\n",
    "pseudobulk_df = pseudobulk_df[pseudobulk_df.index.isin(gene_ids)]\n",
    "\n",
    "pseudobulk_df['gene_id'] = pseudobulk_df.index\n",
    "\n",
    "# Move gene_id to the first column (optional)\n",
    "cols = ['gene_id'] + [col for col in pseudobulk_df.columns if col != 'gene_id']\n",
    "pseudobulk_df = pseudobulk_df[cols]\n",
    "\n",
    "pseudobulk_df.to_csv('../../../../data/kang.tn.filtered.pseudobulk.expression.txt', sep='\\t', index=False)\n",
    "\n",
    "##\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assume oSC is your AnnData object and oSC.obs['sampleName'] contains the labels\n",
    "\n",
    "# 1. Convert the count matrix to a DataFrame (genes as rows, cells as columns)\n",
    "counts_df = pd.DataFrame(\n",
    "    oSC.X.toarray() if hasattr(oSC.X, \"toarray\") else oSC.X,\n",
    "    index=oSC.obs_names,\n",
    "    columns=oSC.var_names\n",
    ")\n",
    "\n",
    "# 2. Add sampleName as a column\n",
    "counts_df['sampleName'] = oSC.obs['sampleName'].values\n",
    "\n",
    "# 3. Group by sampleName and average (mean) across all cells with the same label\n",
    "pseudobulk = counts_df.groupby('sampleName').mean()\n",
    "\n",
    "# 4. (Optional) If you want genes as rows and sampleNames as columns, transpose:\n",
    "# pseudobulk = pseudobulk.T\n",
    "\n",
    "# pseudobulk now contains the average expression for each gene per sampleName\n",
    "\n",
    "\n",
    "##################################\n",
    "## Downsampling using geosketch ##\n",
    "##################################\n",
    "## To keep things simple, we will downsize using geo sketch\n",
    "from geosketch import gs\n",
    "\n",
    "sc.pp.pca(oSC, n_comps=50, key_added=\"X_pca\")\n",
    "N = 500000 # Number of samples to obtain from the data set.\n",
    "X_dimred = oSC.obsm['X_pca']\n",
    "sketch_index = gs(X_dimred, N, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oSC.shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b33f6-7cbf-41b4-b43a-996208b8f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6070bd83-29bc-4f32-918e-93f445a7c329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nemo/stp/babs/working/boeings/Projects/boeings/stefan.boeing/625_liver_cancer_target_report/scripts/targetreport/analyses/main_report_ipynb'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b17998-efd6-465f-abf0-bb08ba53ef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 890528 × 36601\n",
       "    obs: 'Dataset', 'Organ_origin', 'Sample', 'Patient', 'Tissue', 'Cancer type', 'cnv_status', 'Celltype', 'sample', 'patientID', 'sampleName', 'clusterName'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "fno = \"../../../../data/kang_tn_filtered.h5ad\"\n",
    "oSC = sc.read_h5ad(fno)\n",
    "oSC.obs['clusterName'] = oSC.obs['Celltype']\n",
    "oSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb28ce1-715e-4663-8f5a-af7e6eb16da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(\n",
    "    dpi=80,\n",
    "    facecolor=\"White\",\n",
    "    frameon=False\n",
    ")\n",
    "\n",
    "sc.pp.highly_variable_genes(oSC, flavour=\"seurat_v3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ad6f6-f07a-4d70-ae78-33c0d539a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(oSC)\n",
    "sc.pp.neighbors(oSC)\n",
    "sc.tl.umap(oSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11174b-8783-4e12-92f8-8c8bc1740acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(oSC, color = \"clusterName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04e2eb-16b2-4489-a677-c662bdaa3de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
