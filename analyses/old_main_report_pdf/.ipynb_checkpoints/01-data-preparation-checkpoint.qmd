---
format: pdf
---


```{r, echo=FALSE, include=FALSE}
## Determine code visibility
show_code = TRUE

## Don't delete this section if python is required in this analysis section. 
library(reticulate)
```

# Data Preparation

## Obtaining Depmap Data

Depmap source files are obtained programatically from the [Depmap data website]("https://depmap.org/portal/data_page/?tab=overview") using the script below.

Depmap data is compiled into a mudata object for subsequent multiomics analysis. For demonstration purposes also a python `depmap_data` object is created. 

```{python, echo=show_code}

import pandas as pd
import numpy as np
import requests
from io import StringIO
import anndata
import mudata

def get_depmap_files(files_url = "https://depmap.org/portal/api/download/files"):
        """Fetch available DepMap files from the portal API"""
        response = requests.get(files_url, timeout=30)
        response.raise_for_status()
        return pd.read_csv(StringIO(response.text))


def load_depmap_file(filename, df_files_filt):
    """Load depmap file, but stop if filename not found."""
    file_sel_df = df_files_filt[df_files_filt['filename'].str.contains(filename)]
    if file_sel_df.empty:
        raise ValueError(f"File matching '{filename}' not found in df_files_filt.")
    file_url = file_sel_df["url"].values[0]
    response = requests.get(file_url, timeout=30)
    response.raise_for_status()
    if filename.endswith('.csv'):
        df_file = pd.read_csv(StringIO(response.text))
    elif filename.endswith('.txt'):
        df_file = pd.read_csv(StringIO(response.text), sep="\t")
    else:
        raise ValueError("Unsupported file type")
    return df_file  

## Get recent file list
df_files = get_depmap_files(files_url = "https://depmap.org/portal/api/download/files")

## For duplicated files, keep only the most recent version
# Sort by release_date descending, then drop duplicates keeping the first (latest)
df_files_filt = df_files.sort_values('release_date', ascending=False).drop_duplicates(subset='filename', keep='first')

# tpm OmicsExpressionAllGenesTPMLogp1StrandedProfile.csv
#filename = "OmicsExpressionAllGenesTPMLogp1StrandedProfile.csv"
# filename = "OmicsExpressionTPMLogp1HumanAllGenesStranded.csv"


## Get metadata
# metadata cell lines, screens, genes
filename = "Model.csv"
df_metadata = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
# Set modelID as index in df_metadata for easy alignment
df_metadata = df_metadata.set_index('ModelID')

filename = "OmicsProfiles.csv"
df_profiles = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_profiles = df_profiles.set_index('ModelID')

## File selections were made based on paths in https://depmap.org/portal/data_page/?tab=customDownloads

###############################################################################
## Create TPM anndata object                                                 ##
import anndata
import pandas as pd

filename = "OmicsExpressionTPMLogp1HumanProteinCodingGenes.csv"
df_tpm = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_tpm = df_tpm[df_tpm["IsDefaultEntryForModel"] == "Yes"]
df_tpm = df_tpm.set_index('ModelID')
cols_to_delete = df_tpm.columns.to_list()[0:5]
cols_to_delete
df_tpm_adata = df_tpm.drop(columns=cols_to_delete)
df_tpm_adata.columns = [col.split(" (")[0] for col in df_tpm_adata.columns]
# Check if columns are unique
df_tpm_adata.columns.is_unique
df_tpm_adata.index.is_unique

# If df_tpm_adata has features as row index and gene names as columns
  # Transpose to have samples/cells as rows and features/genes as columns
adata_tpm = anndata.AnnData(
    X=df_tpm_adata.values,
    obs=pd.DataFrame(index=df_tpm_adata.index),   # samples/cells
    var=pd.DataFrame(index=df_tpm_adata.columns)      # features/genes
)

adata_tpm.obs = adata_tpm.obs.join(df_metadata)


## Done with TPM anndata object                                              ##
###############################################################################

###############################################################################
## Create count data object for differential gene expression                 ##
filename = "OmicsExpressionRawReadCountHumanProteinCodingGenes.csv"
df_counts = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_counts = df_counts[df_counts["IsDefaultEntryForModel"] == "Yes"]
df_counts = df_counts.set_index('ModelID')
cols_to_delete = df_counts.columns.to_list()[0:5]
cols_to_delete
df_counts_adata = df_counts.drop(columns=cols_to_delete)
df_counts_adata.columns = [col.split(" (")[0] for col in df_counts_adata.columns]
# Check if rows and columns are unique
df_counts_adata.columns.is_unique
df_counts_adata.index.is_unique

## Done counts                                                               ##
###############################################################################

###############################################################################
## Create CRISPR anndata object                                              ##
import anndata
import pandas as pd

filename = "CRISPRGeneEffect.csv"
df_crispr = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_crispr = df_crispr.rename(columns={"Unnamed: 0": "ModelID"})
df_crispr = df_crispr.set_index('ModelID')
df_crispr.columns = [col.split(" (")[0] for col in df_crispr.columns]
# Check if columns are unique
df_crispr.columns.is_unique
df_crispr.index.is_unique


# If df_tpm_adata has features as row index and gene names as columns
  # Transpose to have samples/cells as rows and features/genes as columns
adata_crispr = anndata.AnnData(
    X=df_crispr.values,
    obs=pd.DataFrame(index=df_crispr.index),   # samples/cells
    var=pd.DataFrame(index=df_crispr.columns)      # features/genes
)

adata_crispr.obs = adata_crispr.obs.join(df_metadata)


## Done with TPM anndata object                                              ##
###############################################################################



###############################################################################
## drug response                                                             ##

# drug response metadata
# Create a lookup table between sampleIDs and compound names
filename = "PortalCompounds.csv"
df_compounds = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_rename = df_compounds[['CompoundName', 'SampleIDs']]
df_compounds = df_compounds.set_index('SampleIDs')


filename = "../../../../data/depmap/Repurposing_Public_24Q2_Extended_Primary_Data_Matrix.csv"
df_drugs = pd.read_csv(filename )
df_drugs = df_drugs.rename(columns={"Unnamed: 0": "SampleIDs"})
df_drugs = df_drugs.set_index('SampleIDs')

df_drugs = df_drugs.T

df_drugs.columns.is_unique
df_drugs.index.is_unique

adata_drugs = anndata.AnnData(
    X=df_drugs.values,
    obs=pd.DataFrame(index=df_drugs.index),   # samples/cells
    var=pd.DataFrame(index=df_drugs.columns)      # features/genes/drugs
)

## cell line level metadata
adata_drugs.obs = adata_drugs.obs.join(df_metadata)

## Add drug metadata (added to columns)
adata_drugs.var = adata_drugs.var.join(df_compounds, how='left')



## Done                                                                      ##
###############################################################################

###############################################################################
## Copy number variation (CNV)                                               ##

#CN
#filename="OmicsCNGene.csv"
filename="PortalOmicsCNGeneLog2.csv"
df_cn = load_depmap_file(filename = filename, df_files_filt = df_files_filt)
df_cn = df_cn.rename(columns={"Unnamed: 0": "ModelID"})
df_cn = df_cn.set_index('ModelID')
df_cn.columns = [col.split(" (")[0] for col in df_cn.columns]

## keep only column present in df_tpm_adata
df_cn = df_cn[df_cn.columns.intersection(df_tpm_adata.columns)]
df_cn.columns.is_unique
df_cn.index.is_unique

adata_cn = anndata.AnnData(
    X=df_cn.values,
    obs=pd.DataFrame(index=df_cn.index),   # samples/cells
    var=pd.DataFrame(index=df_cn.columns)      # features/genes
)

adata_cn.obs = adata_cn.obs.join(df_metadata)

## Done                                                                      ##
###############################################################################

###############################################################################
## protein                                                                   ##
## to be added later - required Uniprot > gene name conversion
filename = "harmonized_RPPA_CCLE.csv"
df_protein = load_depmap_file(filename = filename, df_files_filt = df_files_filt)

## Done                                                                      ##
###############################################################################

###############################################################################
## Other data modalities could be added as needed                            ##

# rnai - can be added later. 
filename = "D2_combined_gene_dep_scores.csv"
df_rnai = load_depmap_file(filename = filename, df_files_filt = df_files_filt)

filename = "Repurposing_Public_24Q2_Extended_Primary_Data_Matrix.csv"
df_drugs = load_depmap_file(filename = filename, df_files_filt = df_files_filt)

# methylation
filename = "CCLE_RRBS_TSS_1kb_20180614.txt"
df_methylation = load_depmap_file(filename = filename, df_files_filt = df_files_filt)

## Done optional additions                                                   ##
###############################################################################





##################################################################################
## Initialize depmap data object with loaded datasets                           ##


from wrangle_depmap_data import depmapData

depmap_data = depmapData(
    df_tpm=df_tpm_adata,
    df_counts=df_counts_adata,
    df_cn=df_cn,
    df_drugs=df_drugs,
    df_crispr=df_crispr,
    df_metadata=df_metadata,
    df_profiles=df_profiles
)

## Inspect
depmap_data.data_shapes()

## Subset to cell lines present in all data modalities ##
common_samples = depmap_data.list_common_cell_lines()
common_features = depmap_data.list_common_features()

## Optional: Subset to common cell lines ##
depmap_data_common = depmap_data.subset_to_common_cell_lines()
depmap_data_common.data_shapes()

## Optional: Select features of interest ##
depmap_data_consensus = depmap_data_common.subset_to_common_features()
depmap_data_consensus.data_shapes()

## Optional: Further subset cells ##
depmap_data_min = depmap_data_consensus.subset_to_random_cells(n_cells = 100)
depmap_data_min.data_shapes()

## Check if features of interest are present in all or some modalities
feature_check = depmap_data_consensus.feature_presence(['EZH1', 'EZH2', 'STK19', 'C7orf26'])


## Check if features of interest are present in the various data modalities
for key, value in feature_check.items():
    print(f"Feature: {key}, Present in: {value}")


## save to file ##
outputfile = "../../../../data/depmap/depmap_data_object.pkl"
depmap_data.save_data(filepath=outputfile)

###################################
## Loading depmap dataset object ##
###################################

import os

if os.path.exists(outputfile):
    print(f"Loading existing depmap_data from {outputfile}")
    depmap_data = depmapData.load_data(outputfile)
else:
    print(f"File {outputfile} not found, using newly created depmap_data object")
    # depmap_data already exists from the creation code above

#####################################
## Done loading depmap data object ##
#####################################

```

## Obtaining GTEx data
GTEx data is downloaded from the GTEx website. 

```{python, echo=show_code}

import pandas as pd
import numpy as np

## Step 1: Load metadata
## Setep 2: Subset metadata 
## step 3 : preare count data
## step 4: prepare tpm data

FNmeta = "/nemo/stp/babs/working/boeings/Projects/boeings/stefan.boeing/620_demo_GTEx/data/GTEx_Analysis_v10_Annotations_SampleAttributesDS.txt"

df_meta = pd.read_csv(
    FNmeta,
    sep="\t"
)
df_meta_sel = df_meta[['SAMPID', 'SMTS', 'SMAFRZE']].copy()

## Add Subjid
df_meta_sel['SUBJID'] = df_meta_sel['SAMPID'].str.split('-').str[:2].str.join('-')


## Load phenotype data
FNmeta = "/nemo/stp/babs/working/boeings/Projects/boeings/stefan.boeing/620_demo_GTEx/data/GTEx_Analysis_v10_Annotations_SubjectPhenotypesDS.txt"
df_pheno = pd.read_csv(
    FNmeta,
    sep="\t"
)

df_joined = pd.merge(df_pheno, df_meta_sel, on="SUBJID", how="inner")
df_joined['SEX'] = df_joined['SEX'].replace({1: 'M', 2: 'F'})
df_joined['SMTS'] = df_joined['SMTS'].str.replace(' ', '')

## Filter for specific tissue or subset ##
## Filter on Method
## List all methods
available_methods = sorted(df_joined['SMAFRZE'].dropna().unique().tolist())
print(f"Available methods: {available_methods}")

## Filter on RNASeq
df_gtex_meta = df_joined[df_joined['SMAFRZE'] == 'RNASEQ']

df_gtex_meta.set_index('SAMPID', inplace=True)

## List available tissue
available_tissues = sorted(df_gtex_meta['SMTS'].dropna().unique())
print(f"Available tissues: {available_tissues}")

## Optional filtering on tissue ##

## Optional filtering on age range ##



## Optional: plot gender/age/organ distribution ##

######################################
## Load gtex  count data and subset ##
######################################

## Load count data
##    Selections: column names / cell ids
##    Min-count per row filtering (default row mean >= 1)

FNgtex = "/nemo/stp/babs/working/boeings/Projects/boeings/stefan.boeing/620_demo_GTEx/data/GTEx_Analysis_v10_RNASeQCv2.4.2_gene_reads.gct.gz"
df_count_gtex = pd.read_csv(
    FNgtex,
    sep="\t",
    skiprows=2
)
df_count_gtex.shape
## To speed up DGE comparisons, filter for lowly expressed genes. 
## Here we will require at least one count per sample on average
df_count_gtex.rename(columns={'Description': 'gene_id'}, inplace=True)
df_count_gtex.set_index('gene_id', inplace=True)

numeric_cols = df_count_gtex.select_dtypes(include='number').columns

df_count_gtex = df_count_gtex[numeric_cols]

## Check df_count_gtext
# Get all sample IDs present in the metadata
sampid_set = set(df_gtex_meta.index)


# Convert column names to set for faster lookup
gtex_columns = set(df_count_gtex.columns)

# Filter the list
sampid_set = [sample_id for sample_id in sampid_set if sample_id in gtex_columns]

## Select random sample ids ##
# Randomly select n_samples rows from the dataframe
n_samples = 100
n_to_select = min(n_samples, len(sampid_set))
subset_sample_ids = np.random.choice(sampid_set, size=n_to_select, replace=False).tolist()

df_count_gtex_subset = df_count_gtex[subset_sample_ids]
df_count_gtex = df_count_gtex_subset.copy()

## Filter features based on row averages ##

min_rowcount = 1 * len(df_count_gtex_subset.columns)


df_count_gtex = df_count_gtex[df_count_gtex.mean(axis=1) >= min_rowcount]
df_count_gtex.shape

#############################################
## Load tpm data based on count selections ##
#############################################

samples = df_count_gtex.columns.tolist()
features = df_count_gtex.index.tolist()

## Load tpm data ##
FNgtex_tpm = "/nemo/stp/babs/working/boeings/Projects/boeings/stefan.boeing/620_demo_GTEx/data/GTEx_Analysis_v10_RNASeQCv2.4.2_gene_tpm.gct.gz"
df_tpm_gtex = pd.read_csv(
    FNgtex_tpm,
    sep="\t",
    skiprows=2
)
df_tpm_gtex.shape

df_tpm_gtex.rename(columns={'Description': 'gene_id'}, inplace=True)
df_tpm_gtex.set_index('gene_id', inplace=True)

numeric_cols = df_tpm_gtex.select_dtypes(include='number').columns

df_tpm_gtex = df_tpm_gtex[numeric_cols]

# Get intersection of available features and samples
available_features = [f for f in features if f in df_tpm_gtex.index]
available_samples = [s for s in samples if s in df_tpm_gtex.columns]

# Subset the DataFrame
df_tpm_gtex = df_tpm_gtex.loc[available_features, available_samples]

# subset metadata
df_gtex_meta = df_gtex_meta.loc[available_samples, :]

##########################
## Obtaining GTEx Data  ##
##########################



from wrangle_gtex_data import gtexData

gtex_data = gtexData(
    df_metadata=df_gtex_meta,
    df_tpm=df_tpm_gtex,
    df_counts=df_count_gtex,
)

gtex_data.data_shapes()
```

## Data for bulkRNAseq Analysis
A read count matrix and corresponding intensity matrix/TPM file is obtained

```{python, echo=show_code}
#################################
## Obtaining DGE dataset       ##
#################################

## DGE Processing - see separate script ##

## Transforming (sketched) single cell dataset into per sample bulkRNAseq ##

FNcount_matrix = "/nemo/stp/babs/working/boeings/projects/boeings/stefan.boeing/621_demo_liverdemo_bulkRNAseq/data/rsem.count.txt"
dfcount = pd.read_csv(FNcount_matrix, sep="\t")

FNexpr_matrix = "/nemo/stp/babs/working/boeings/projects/boeings/stefan.boeing/621_demo_liverdemo_bulkRNAseq/data/dfTPM.txt"
dftpm = pd.read_csv(FNexpr_matrix, sep="\t")

FNdesign = "/nemo/stp/babs/working/boeings/projects/boeings/stefan.boeing/621_demo_liverdemo_bulkRNAseq/scripts/bulkliverdemo/design/design.table.txt"
dfDesign = pd.read_csv(FNdesign, sep="\t")

```


## Data for single-cell Analysis
A read count matrix and corresponding intensity matrix/TPM file is obtained

```{python, echo=show_code}
#################################
## Obtaining DGE dataset       ##
#################################

## Single-cell dataset was 


```